{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, svm,naive_bayes\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SADMAN\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:587: FutureWarning: Pass sampling_strategy=minority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "smote=SMOTE(\"minority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"cleaned2.csv\")\n",
    "df2=df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_merged</th>\n",
       "      <th>text</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>['hackers', 'target', 'presidential', 'candida...</td>\n",
       "      <td>['hacker', 'target', 'presidential', 'candidat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARENTING</td>\n",
       "      <td>['the', 'royal', 'birth', 'cost', '$', '15,000...</td>\n",
       "      <td>['royal', 'birth', 'cost', 'average', 'america...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>['of', 'winners', 'and', 'losers', 'in', 'my',...</td>\n",
       "      <td>['winner', 'loser', 'travel', 'around', 'world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>['nan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>['10', 'ways', 'to', 'not', 'be', 'a', 'total'...</td>\n",
       "      <td>['way', 'total', 'jerk', 'next', 'flight', 'sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200848</th>\n",
       "      <td>IMPACT</td>\n",
       "      <td>['this', 'asian', 'girl', 'anthem', 'is', 'for...</td>\n",
       "      <td>['asian', 'girl', 'anthem', 'yellow', 'girl', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200849</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>['7', 'steps', 'to', 'reframe', 'and', 'change...</td>\n",
       "      <td>['step', 'reframe', 'change', 'relationship', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200850</th>\n",
       "      <td>GROUPS VOICES</td>\n",
       "      <td>['cyndi', 'lauper', 'plans', 'incredible', 'sh...</td>\n",
       "      <td>['cyndi', 'lauper', 'plan', 'incredible', 'sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200851</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>['how', 'to', 'steal', 'a', 'nomination', 'fro...</td>\n",
       "      <td>['steal', 'nomination', 'donald', 'trump', 'in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200852</th>\n",
       "      <td>IMPACT</td>\n",
       "      <td>['a', 'silver', 'lining', 'for', 'the', 'ebola...</td>\n",
       "      <td>['silver', 'lining', 'ebola', 'crisis', 'dark'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200853 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category_merged                                               text  \\\n",
       "0             POLITICS  ['hackers', 'target', 'presidential', 'candida...   \n",
       "1            PARENTING  ['the', 'royal', 'birth', 'cost', '$', '15,000...   \n",
       "2             WELLNESS  ['of', 'winners', 'and', 'losers', 'in', 'my',...   \n",
       "3             WELLNESS                                            ['nan']   \n",
       "4               TRAVEL  ['10', 'ways', 'to', 'not', 'be', 'a', 'total'...   \n",
       "...                ...                                                ...   \n",
       "200848          IMPACT  ['this', 'asian', 'girl', 'anthem', 'is', 'for...   \n",
       "200849        WELLNESS  ['7', 'steps', 'to', 'reframe', 'and', 'change...   \n",
       "200850   GROUPS VOICES  ['cyndi', 'lauper', 'plans', 'incredible', 'sh...   \n",
       "200851        POLITICS  ['how', 'to', 'steal', 'a', 'nomination', 'fro...   \n",
       "200852          IMPACT  ['a', 'silver', 'lining', 'for', 'the', 'ebola...   \n",
       "\n",
       "                                               text_final  \n",
       "0       ['hacker', 'target', 'presidential', 'candidat...  \n",
       "1       ['royal', 'birth', 'cost', 'average', 'america...  \n",
       "2       ['winner', 'loser', 'travel', 'around', 'world...  \n",
       "3                                                 ['nan']  \n",
       "4       ['way', 'total', 'jerk', 'next', 'flight', 'sh...  \n",
       "...                                                   ...  \n",
       "200848  ['asian', 'girl', 'anthem', 'yellow', 'girl', ...  \n",
       "200849  ['step', 'reframe', 'change', 'relationship', ...  \n",
       "200850  ['cyndi', 'lauper', 'plan', 'incredible', 'sho...  \n",
       "200851  ['steal', 'nomination', 'donald', 'trump', 'in...  \n",
       "200852  ['silver', 'lining', 'ebola', 'crisis', 'dark'...  \n",
       "\n",
       "[200853 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(df2['text_final'],df2['category_merged'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=30000)   \n",
    "Tfidf_vect.fit(df2['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm,Y_sm=smote.fit_resample(Train_X_Tfidf,Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = svm.SVC(C=1, kernel='linear')\n",
    "SVM.fit(X_sm,Y_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "train_accuracy=SVM.predict(X_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score ->  60.36909187466808\n",
      "Train Accuracy Score:  77.71720024916277\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
    "print(\"Train Accuracy Score: \", accuracy_score(Y_sm, train_accuracy)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.38      0.45      1148\n",
      "           1       0.57      0.47      0.51      2309\n",
      "           2       0.57      0.33      0.42      1615\n",
      "           3       0.56      0.43      0.49      1024\n",
      "           4       0.79      0.71      0.75      1033\n",
      "           5       0.06      0.62      0.11       652\n",
      "           6       0.59      0.58      0.58      4826\n",
      "           7       0.53      0.44      0.48      1199\n",
      "           8       0.76      0.79      0.77      2533\n",
      "           9       0.66      0.47      0.55      3662\n",
      "          10       0.76      0.73      0.74      1202\n",
      "          11       0.45      0.21      0.28      1047\n",
      "          12       0.55      0.31      0.39       808\n",
      "          13       0.41      0.08      0.13       870\n",
      "          14       0.66      0.67      0.67      3746\n",
      "          15       0.71      0.73      0.72      9697\n",
      "          16       0.56      0.32      0.41       738\n",
      "          17       0.61      0.42      0.50      1291\n",
      "          18       0.70      0.59      0.64      1476\n",
      "          19       0.80      0.73      0.76      3523\n",
      "          20       0.74      0.72      0.73      2950\n",
      "          21       0.78      0.77      0.78      1086\n",
      "          22       0.44      0.20      0.27       780\n",
      "          23       0.67      0.76      0.71      7417\n",
      "          24       0.41      0.29      0.34      1074\n",
      "          25       0.71      0.54      0.62      2550\n",
      "\n",
      "    accuracy                           0.60     60256\n",
      "   macro avg       0.60      0.51      0.53     60256\n",
      "weighted avg       0.65      0.60      0.62     60256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, predictions_SVM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 440    9   12    0    2  209  152    5    7   47   11    5    2    0\n",
      "    17   45    3   10    2   24   51    1    5   61   22    6]\n",
      " [  10 1081    4   19    4  285   34   33   37   18   19   24    6    1\n",
      "    53  244    1   49   17   22   37    7    4  240   24   36]\n",
      " [  12   28  539    1    3  243  224   19   29   34    8    0   14    3\n",
      "    60  187   10   25   24   32    9    8   17   70   11    5]\n",
      " [   2    5    1  443    1  224   34    7    3   36    4    3    1    3\n",
      "    23  137    4    4    5    2   12    1   18   23    6   22]\n",
      " [   2    5    3    1  734    1   31    2    1   10    4    1    1    4\n",
      "    56   10    1    2    3    9    5   58    3   74   12    0]\n",
      " [   5   25    2    6    0  404    8    2    2   15    2   13    2    1\n",
      "    42   49    1    6    5    2    6    1    0   43    5    5]\n",
      " [  74   21  135   31   28  802 2787   11   27  170   10    6    9    4\n",
      "   105  221    7   14   35   94   33   20    8  114   50   10]\n",
      " [   3   24    7    3    1  186   21  530   15    3   12   15    3   16\n",
      "    24  143    3   23    4    8   49    1   18   65    2   20]\n",
      " [   3   14   20    0    3   46   43    8 1997    7   31    4    0    2\n",
      "    38   20    5   10    8   22   71    2   13  163    0    3]\n",
      " [  42   31    8   71   11  431  353    4   20 1707    7   21   20    5\n",
      "    95  403   22    9   53   61   37   30    5  147   38   31]\n",
      " [  12   23    4    2    1    3   22   11   48    2  875    2    0    0\n",
      "    16    7    0    2    2   58   39    3    2   65    3    0]\n",
      " [   7   49    1    1    3  154   26   31   16   33    6  216    4    5\n",
      "    84  111    3   16   13    7   26    2    3  173   25   32]\n",
      " [   4   16   12    5    0  167   46    3    1    8    0    0  247    0\n",
      "     3  227    2    6    5    5    2    0    1   21    8   19]\n",
      " [  10   22    4    2   13  232   36   30   24   24   12   13    1   67\n",
      "    88   19    2    5    8   17   26    9   18  169   13    6]\n",
      " [  19   37   27   14   22  205  113   13   37   39   25    8    1   12\n",
      "  2526   58    7   24   28   54   31    9   10  389   32    6]\n",
      " [  19  154   45   78    1 1044  118  104   12  183    6   33   83    4\n",
      "    60 7122   52   25   31   11   45    6    6  155   63  237]\n",
      " [   5    6    4    5    2  218   14    2    4   33    2    7    3    2\n",
      "    14   75  237    1    4    2    3    2    1   70    3   19]\n",
      " [  14   83   10    9    2  136   49   45   10    8    6    4   10    0\n",
      "    31   77    4  540    8   16   25    3   10  161   15   15]\n",
      " [   3    4   22   16    1  213   81    4    6   37    1    6    6    2\n",
      "    23   65    1    0  869   11   17    2   15   46   12   13]\n",
      " [  18   29   20    1    5  224  146   12   29   44   37    3    2    4\n",
      "    66   49    3   11   14 2578   51   30    6  106   31    4]\n",
      " [  31   36    5    4    5  139   66   29  109   15   23    6    4    2\n",
      "    45   52   11   15   14   41 2113   14    5  121    5   40]\n",
      " [   1    6    4    2   40    1   39    0    9   14    4    2    1    1\n",
      "    16   11    1    2    1   28   13  838    2   48    2    0]\n",
      " [  11   15   26   45    3  139   83   19   32    9    7    1    2    8\n",
      "    33   51    3   14   21   17   26    3  153   46    5    8]\n",
      " [  31   98   15    8   29  469   93   34  144   33   35   41   11    8\n",
      "   229  169    8   50   39   63   89   11   15 5642   41   12]\n",
      " [   3   32   11    5    8  132   76    0    2   32    5    8    5    5\n",
      "    67  142    3    7    6   25    6   12    1  167  312    2]\n",
      " [  13   41    5   23    2  415   23   45    3   29    0   39   11    3\n",
      "    11  310   33   14   17    8   48    2    5   53   18 1379]]\n"
     ]
    }
   ],
   "source": [
    "results = confusion_matrix(Test_Y,predictions_SVM )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
